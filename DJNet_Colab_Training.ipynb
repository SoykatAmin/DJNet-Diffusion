{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15208b72",
   "metadata": {},
   "source": [
    "# DJNet-Diffusion Training on Colab/Kaggle\n",
    "\n",
    "This notebook trains the DJNet diffusion model for music transition generation.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Upload your dataset to Colab/Kaggle\n",
    "2. Update the paths in the configuration\n",
    "3. Run all cells to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec07289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchaudio diffusers transformers accelerate librosa soundfile\n",
    "!pip install pandas numpy matplotlib seaborn tensorboard tqdm scipy omegaconf wandb scikit-learn PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and extract your DJNet code\n",
    "# You can zip your local implementation and upload it here\n",
    "# !unzip djnet-diffusion.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dca008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or pull the latest DJNet implementation\n",
    "# !git clone https://github.com/SoykatAmin/DJNet-Diffusion.git djnet-diffusion\n",
    "# If already cloned, pull latest changes:\n",
    "# !cd djnet-diffusion && git pull origin main\n",
    "\n",
    "# Or if you have a zip file, upload and extract:\n",
    "# !unzip djnet-diffusion.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\" if torch.cuda.is_available() else \"No CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to match your Colab/Kaggle setup\n",
    "import yaml\n",
    "\n",
    "# Training configuration for GPU\n",
    "training_config = {\n",
    "    'training': {\n",
    "        'batch_size': 16,  # Larger batch size for GPU\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-6,\n",
    "        'warmup_steps': 1000,\n",
    "        'gradient_clip_norm': 1.0,\n",
    "        'save_every_n_epochs': 5,\n",
    "        'validate_every_n_epochs': 2\n",
    "    },\n",
    "    'data': {\n",
    "        'metadata_path': '/content/metadata.csv',  # Update this path\n",
    "        'data_root': '/content/djnet_dataset_20k',  # Update this path\n",
    "        'train_split': 0.8,\n",
    "        'val_split': 0.1,\n",
    "        'test_split': 0.1,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'shuffle': True\n",
    "    },\n",
    "    'logging': {\n",
    "        'log_dir': 'logs',\n",
    "        'use_wandb': False,  # Set to True if you want to use wandb\n",
    "        'wandb_project': 'djnet-diffusion',\n",
    "        'log_every_n_steps': 50,\n",
    "        'save_audio_samples': True,\n",
    "        'num_audio_samples': 4\n",
    "    },\n",
    "    'optimization': {\n",
    "        'optimizer': 'AdamW',\n",
    "        'scheduler': 'cosine',\n",
    "        'min_lr': 1e-6\n",
    "    },\n",
    "    'checkpointing': {\n",
    "        'checkpoint_dir': 'checkpoints',\n",
    "        'resume_from_checkpoint': None,\n",
    "        'save_best_only': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Model configuration for GPU\n",
    "model_config = {\n",
    "    'model': {\n",
    "        'name': 'DJNetDiffusion',\n",
    "        'in_channels': 3,\n",
    "        'out_channels': 1,\n",
    "        'down_block_types': ['DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D'],\n",
    "        'up_block_types': ['AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D'],\n",
    "        'block_out_channels': [128, 256, 512, 512],\n",
    "        'layers_per_block': 2,\n",
    "        'attention_head_dim': 8,\n",
    "        'norm_num_groups': 32,\n",
    "        'cross_attention_dim': 256\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'num_train_timesteps': 1000,\n",
    "        'beta_start': 0.0001,\n",
    "        'beta_end': 0.02,\n",
    "        'beta_schedule': 'linear',\n",
    "        'variance_type': 'fixed_small',\n",
    "        'clip_sample': False\n",
    "    },\n",
    "    'audio': {\n",
    "        'sample_rate': 22050,\n",
    "        'n_mels': 128,\n",
    "        'n_fft': 2048,\n",
    "        'hop_length': 512,\n",
    "        'win_length': 2048,\n",
    "        'context_duration': 4.0,\n",
    "        'max_transition_duration': 8.0,\n",
    "        'normalize_spectrograms': True,\n",
    "        'spec_min': -80.0,\n",
    "        'spec_max': 0.0\n",
    "    },\n",
    "    'conditioning': {\n",
    "        'use_tempo': True,\n",
    "        'use_transition_type': True,\n",
    "        'use_transition_length': True,\n",
    "        'tempo_embed_dim': 64,\n",
    "        'type_embed_dim': 64,\n",
    "        'length_embed_dim': 64\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configurations\n",
    "with open('training_config.yaml', 'w') as f:\n",
    "    yaml.dump(training_config, f)\n",
    "    \n",
    "with open('model_config.yaml', 'w') as f:\n",
    "    yaml.dump(model_config, f)\n",
    "\n",
    "print(\"‚úÖ Configuration files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac881c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your DJNet implementation\n",
    "import sys\n",
    "sys.path.append('/content/djnet-diffusion')  # Update path as needed\n",
    "\n",
    "from src.training.trainer import DJNetTrainer, load_config\n",
    "print(\"‚úÖ DJNet modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c85d3",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important: Latest Fixes Applied\n",
    "\n",
    "**The latest version includes critical fixes for:**\n",
    "- Tensor dimension consistency in training and inference\n",
    "- Custom collate function for proper batching\n",
    "- Spectrogram size normalization\n",
    "\n",
    "**Make sure to pull the latest changes before training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd383652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations and start training\n",
    "training_config = load_config('training_config.yaml')\n",
    "model_config = load_config('model_config.yaml')\n",
    "config = {**model_config, **training_config}\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DJNetTrainer(config, device)\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in trainer.model.parameters()):,} parameters\")\n",
    "print(f\"Training dataset size: {len(trainer.train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(trainer.val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb82bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"üéâ Training completed successfully!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user\")\n",
    "    trainer.save_checkpoint(trainer.current_epoch, is_best=False)\n",
    "    print(\"Checkpoint saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation with trained model\n",
    "from inference.generator import DJNetGenerator\n",
    "\n",
    "# Load best model\n",
    "checkpoint_path = 'checkpoints/best_model.pth'\n",
    "generator = DJNetGenerator(checkpoint_path, device)\n",
    "\n",
    "print(\"‚úÖ Generator loaded successfully\")\n",
    "print(\"Ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example generation (update paths to your test audio files)\n",
    "output_path = generator.generate_transition_audio(\n",
    "    song_a_path='/content/test_song_a.wav',  # Update this\n",
    "    song_b_path='/content/test_song_b.wav',  # Update this\n",
    "    output_path='/content/generated_transition.wav',\n",
    "    transition_length=8.0,\n",
    "    tempo=120.0,\n",
    "    transition_type='linear_fade',\n",
    "    num_inference_steps=50\n",
    ")\n",
    "\n",
    "print(f\"Generated transition: {output_path}\")\n",
    "\n",
    "# Play the result\n",
    "from IPython.display import Audio\n",
    "Audio(output_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
